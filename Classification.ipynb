{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8e9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "SENTINEL = 1e99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53da652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1. Load datasets and preprocess\n",
    "# ========================================\n",
    "def load_and_preprocess(train_data_file, train_label_file, test_data_file, sentinel=SENTINEL):\n",
    "    \"\"\"\n",
    "    Load train/test, replace sentinel with NaN, then impute column means (from train).\n",
    "    Returns: X, y, test_df\n",
    "    \"\"\"\n",
    "    train_X = np.loadtxt(train_data_file)\n",
    "    train_y = np.loadtxt(train_label_file).astype(int)\n",
    "    test_X  = np.loadtxt(test_data_file)\n",
    "\n",
    "    # Replace sentinel with NaN\n",
    "    train_X = np.where(train_X > sentinel/10, np.nan, train_X)\n",
    "    test_X  = np.where(test_X  > sentinel/10, np.nan, test_X)\n",
    "\n",
    "    # Put into DataFrames for easy imputation\n",
    "    train_df = pd.DataFrame(train_X)\n",
    "    test_df  = pd.DataFrame(test_X)\n",
    "\n",
    "    # Impute with column means from training set\n",
    "    col_means = train_df.mean()\n",
    "    train_df = train_df.fillna(col_means)\n",
    "    test_df  = test_df.fillna(col_means)\n",
    "\n",
    "    X = train_df.values\n",
    "    y = train_y\n",
    "    return X, y, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f5345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2. Load and preprocess dataset 1\n",
    "# ========================================\n",
    "X, y, test_df = load_and_preprocess(\n",
    "    \"./classification/TrainData1.txt\",\n",
    "    \"./classification/TrainLabel1.txt\",\n",
    "    \"./classification/TestData1.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023041d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3. Define PCA + SVM pipeline\n",
    "# ===============================\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.95)),  # keep 95% variance\n",
    "    (\"svm\", SVC(kernel=\"linear\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df6853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 4. Define PCA + Logistic Regression pipeline\n",
    "# ===============================\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=0.95)),\n",
    "    (\"logreg\", LogisticRegression(max_iter=500, multi_class=\"auto\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf33f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5. Metrics\n",
    "# ===============================\n",
    "\n",
    "scoring_metrics = {\n",
    "    \"accuracy\":  \"accuracy\",\n",
    "    \"precision\": \"precision_macro\",\n",
    "    \"recall\":    \"recall_macro\",\n",
    "    \"f1\":        \"f1_macro\",\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938767ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5. Compute metrics\n",
    "# ===============================\n",
    "\n",
    "svm_results = {m: cross_val_score(pipe_svm, X, y, cv=cv, scoring=scorer)\n",
    "               for m, scorer in scoring_metrics.items()}\n",
    "lr_results = {m: cross_val_score(pipe_lr, X, y, cv=cv, scoring=scorer)\n",
    "              for m, scorer in scoring_metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27232b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (PCA + SVM) ===\n",
      "Accuracy  : mean=0.9733, std=0.0249, folds=[1.         0.93333333 1.         0.96666667 0.96666667]\n",
      "Precision : mean=0.8974, std=0.0936, folds=[1.         0.90530303 1.         0.79090909 0.79090909]\n",
      "Recall    : mean=0.9011, std=0.0895, folds=[1.         0.90530303 1.         0.8        0.8       ]\n",
      "F1        : mean=0.8992, std=0.0916, folds=[1.         0.90530303 1.         0.79534884 0.79534884]\n",
      "\n",
      "=== Logistic Regression (PCA + Logistic Regression) ===\n",
      "Accuracy  : mean=0.9600, std=0.0327, folds=[0.96666667 0.9        1.         0.96666667 0.96666667]\n",
      "Precision : mean=0.8848, std=0.0925, folds=[0.98913043 0.85326087 1.         0.79090909 0.79090909]\n",
      "Recall    : mean=0.8594, std=0.0755, folds=[0.875     0.8219697 1.        0.8       0.8      ]\n",
      "F1        : mean=0.8670, std=0.0788, folds=[0.91111111 0.83333333 1.         0.79534884 0.79534884]\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 6. Print results\n",
    "# ===============================\n",
    "\n",
    "def print_metrics(name, results):\n",
    "    print(f\"\\n=== {name} (PCA + {name}) ===\")\n",
    "    for m, scores in results.items():\n",
    "        print(f\"{m.capitalize():<10}: mean={scores.mean():.4f}, std={scores.std():.4f}, folds={scores}\")\n",
    "\n",
    "print_metrics(\"SVM\", svm_results)\n",
    "print_metrics(\"Logistic Regression\", lr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "558d437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 7. Fit SVM models fully + predict test\n",
    "# ===========================================================\n",
    "pipe_svm.fit(X, y)\n",
    "svm_pred = pipe_svm.predict(test_df.values)\n",
    "np.savetxt(\"./classification/Dao_Corona_Classification1.txt\",  svm_pred,  fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1fff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 8. Load and preprocess dataset 2\n",
    "# ========================================\n",
    "X2, y2, test2_df = load_and_preprocess(\n",
    "    \"./classification/TrainData2.txt\",\n",
    "    \"./classification/TrainLabel2.txt\",\n",
    "    \"./classification/TestData2.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e07521",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = {m: cross_val_score(pipe_svm, X2, y2, cv=cv, scoring=scorer)\n",
    "               for m, scorer in scoring_metrics.items()}\n",
    "lr_results = {m: cross_val_score(pipe_lr, X2, y2, cv=cv, scoring=scorer)\n",
    "              for m, scorer in scoring_metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb959a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (PCA + SVM) ===\n",
      "Accuracy  : mean=0.8900, std=0.0735, folds=[0.95 0.9  0.75 0.95 0.9 ]\n",
      "Precision : mean=0.9121, std=0.0713, folds=[0.95454545 0.93939394 0.77272727 0.96969697 0.92424242]\n",
      "Recall    : mean=0.8939, std=0.0852, folds=[0.95454545 0.92424242 0.72727273 0.95454545 0.90909091]\n",
      "F1        : mean=0.8782, std=0.0944, folds=[0.93939394 0.91515152 0.69393939 0.95151515 0.89090909]\n",
      "\n",
      "=== Logistic Regression (PCA + Logistic Regression) ===\n",
      "Accuracy  : mean=0.9200, std=0.0400, folds=[0.95 0.9  0.85 0.95 0.95]\n",
      "Precision : mean=0.9455, std=0.0281, folds=[0.95454545 0.93939394 0.89393939 0.96969697 0.96969697]\n",
      "Recall    : mean=0.9303, std=0.0353, folds=[0.95454545 0.92424242 0.86363636 0.95454545 0.95454545]\n",
      "F1        : mean=0.9200, std=0.0410, folds=[0.93939394 0.91515152 0.84242424 0.95151515 0.95151515]\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(name, results):\n",
    "    print(f\"\\n=== {name} (PCA + {name}) ===\")\n",
    "    for m, scores in results.items():\n",
    "        print(f\"{m.capitalize():<10}: mean={scores.mean():.4f}, std={scores.std():.4f}, folds={scores}\")\n",
    "\n",
    "print_metrics(\"SVM\", svm_results)\n",
    "print_metrics(\"Logistic Regression\", lr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff0ff472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 9. Fit Logistics Regression models fully + predict test\n",
    "# ===========================================================\n",
    "pipe_lr.fit(X2, y2)\n",
    "lr_pred = pipe_lr.predict(test2_df.values)\n",
    "np.savetxt(\"./classification/Dao_Corona_Classification2.txt\",  lr_pred,  fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f133a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3, y3, test3_df = load_and_preprocess(\n",
    "    \"./classification/TrainData3.txt\",\n",
    "    \"./classification/TrainLabel3.txt\",\n",
    "    \"./classification/TestData3.txt\"\n",
    ")\n",
    "X4, y4, test4_df = load_and_preprocess(\n",
    "    \"./classification/TrainData4.txt\",\n",
    "    \"./classification/TrainLabel4.txt\",\n",
    "    \"./classification/TestData4.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4537f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Define models\n",
    "# ==================\n",
    "models = {\n",
    "    \"SVM_RBF\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\"))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            multi_class=\"multinomial\",\n",
    "            solver=\"lbfgs\"\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=5))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "317ef20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset 3: SVM_RBF ===\n",
      "Accuracy   mean=0.9144, std=0.0077, folds=[0.91372549 0.90784314 0.90569745 0.91748527 0.92730845]\n",
      "Precision  mean=0.9149, std=0.0076, folds=[0.91391909 0.90836261 0.90628337 0.91821221 0.92757996]\n",
      "Recall     mean=0.9138, std=0.0078, folds=[0.91340227 0.9071333  0.90468655 0.91705867 0.92653686]\n",
      "F1         mean=0.9138, std=0.0079, folds=[0.91335969 0.90717709 0.90442757 0.91711319 0.92672013]\n",
      "\n",
      "=== Dataset 3: RandomForest ===\n",
      "Accuracy   mean=0.9639, std=0.0045, folds=[0.95882353 0.95882353 0.96660118 0.96463654 0.97053045]\n",
      "Precision  mean=0.9650, std=0.0045, folds=[0.95964088 0.96057428 0.96776463 0.96543575 0.97180993]\n",
      "Recall     mean=0.9636, std=0.0045, folds=[0.95884553 0.95846298 0.96642908 0.96435085 0.97009681]\n",
      "F1         mean=0.9638, std=0.0045, folds=[0.95895719 0.95873082 0.96633412 0.96435082 0.97046351]\n",
      "\n",
      "=== Dataset 3: LogisticRegression ===\n",
      "Accuracy   mean=0.8547, std=0.0137, folds=[0.8372549  0.85882353 0.84675835 0.87819253 0.85265226]\n",
      "Precision  mean=0.8557, std=0.0130, folds=[0.83832571 0.85844334 0.85010377 0.87800156 0.85344369]\n",
      "Recall     mean=0.8538, std=0.0136, folds=[0.83698204 0.85753939 0.84531523 0.87717682 0.85209791]\n",
      "F1         mean=0.8533, std=0.0140, folds=[0.83573845 0.85743914 0.84445024 0.87713498 0.85162182]\n",
      "\n",
      "=== Dataset 3: KNN ===\n",
      "Accuracy   mean=0.8378, std=0.0154, folds=[0.85686275 0.81960784 0.82121807 0.8388998  0.85265226]\n",
      "Precision  mean=0.8404, std=0.0144, folds=[0.85802524 0.82188296 0.82674881 0.84067803 0.85441652]\n",
      "Recall     mean=0.8362, std=0.0154, folds=[0.85549222 0.81845094 0.81912036 0.83768292 0.85039051]\n",
      "F1         mean=0.8357, std=0.0151, folds=[0.85473513 0.81891593 0.81816173 0.83783943 0.84909266]\n"
     ]
    }
   ],
   "source": [
    "results_3 = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Dataset 3: {name} ===\")\n",
    "    model_results = {}\n",
    "\n",
    "    for metric_name, scorer in scoring_metrics.items():\n",
    "        scores = cross_val_score(model, X3, y3, cv=cv, scoring=scorer)\n",
    "        model_results[metric_name] = scores\n",
    "        print(f\"{metric_name.capitalize():<10} mean={scores.mean():.4f}, \"\n",
    "              f\"std={scores.std():.4f}, folds={scores}\")\n",
    "\n",
    "    results_3[name] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4df3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset 4: SVM_RBF ===\n",
      "Accuracy   mean=0.6014, std=0.0226, folds=[0.56696429 0.61160714 0.625      0.62053571 0.58295964]\n",
      "Precision  mean=0.2991, std=0.0214, folds=[0.30747126 0.27257816 0.32331254 0.31756509 0.27461859]\n",
      "Recall     mean=0.2790, std=0.0111, folds=[0.27862353 0.26869019 0.29080547 0.29217124 0.26493147]\n",
      "F1         mean=0.2802, std=0.0142, folds=[0.28462838 0.26329998 0.29448683 0.29522914 0.26346932]\n",
      "\n",
      "=== Dataset 4: RandomForest ===\n",
      "Accuracy   mean=0.6792, std=0.0295, folds=[0.63392857 0.70982143 0.69642857 0.70089286 0.65470852]\n",
      "Precision  mean=0.4120, std=0.0755, folds=[0.34167448 0.35424622 0.35781584 0.52136192 0.48495997]\n",
      "Recall     mean=0.3569, std=0.0298, folds=[0.30612205 0.35800687 0.3489812  0.3943626  0.37703535]\n",
      "F1         mean=0.3692, std=0.0396, folds=[0.31370688 0.35490318 0.35014545 0.42494063 0.40224015]\n",
      "\n",
      "=== Dataset 4: LogisticRegression ===\n",
      "Accuracy   mean=0.5996, std=0.0167, folds=[0.58035714 0.58482143 0.61160714 0.625      0.59641256]\n",
      "Precision  mean=0.3569, std=0.0761, folds=[0.30069794 0.27081401 0.31635031 0.45106604 0.44565387]\n",
      "Recall     mean=0.3033, std=0.0364, folds=[0.27968869 0.26578014 0.29802432 0.37143089 0.30135085]\n",
      "F1         mean=0.3118, std=0.0453, folds=[0.28412974 0.26315407 0.30151591 0.39562908 0.31443845]\n",
      "\n",
      "=== Dataset 4: KNN ===\n",
      "Accuracy   mean=0.5541, std=0.0186, folds=[0.54910714 0.53571429 0.58928571 0.55357143 0.5426009 ]\n",
      "Precision  mean=0.2823, std=0.0126, folds=[0.29031465 0.25881071 0.29185636 0.27914168 0.29125017]\n",
      "Recall     mean=0.2758, std=0.0071, folds=[0.27160598 0.27032815 0.28450692 0.28435017 0.26813392]\n",
      "F1         mean=0.2760, std=0.0076, folds=[0.27583774 0.26314183 0.28543814 0.28170947 0.27405183]\n"
     ]
    }
   ],
   "source": [
    "results_4 = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Dataset 4: {name} ===\")\n",
    "    cv_res = cross_validate(model, X4, y4, cv=cv, scoring=scoring_metrics)\n",
    "\n",
    "    model_results = {}\n",
    "    for metric_name in scoring_metrics.keys():\n",
    "        scores = cv_res[f\"test_{metric_name}\"]\n",
    "        model_results[metric_name] = scores\n",
    "        print(f\"{metric_name.capitalize():<10} mean={scores.mean():.4f}, \"\n",
    "              f\"std={scores.std():.4f}, folds={scores}\")\n",
    "\n",
    "    results_4[name] = model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06a67706",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "# ===== Train on full Dataset 3 =====\n",
    "rf.fit(X3, y3)\n",
    "\n",
    "# ===== Predict test3 =====\n",
    "test3_pred = rf.predict(test3_df.values)\n",
    "np.savetxt(\"./classification/Dao_Corona_Classification3.txt\", test3_pred, fmt=\"%d\")\n",
    "\n",
    "# ===== Train on full Dataset 3 =====\n",
    "rf.fit(X4, y4)\n",
    "\n",
    "# ===== Predict test4 =====\n",
    "test4_pred = rf.predict(test4_df.values)\n",
    "np.savetxt(\"./classification/Dao_Corona_Classification4.txt\", test4_pred, fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
