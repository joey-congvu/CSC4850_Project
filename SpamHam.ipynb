{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b9af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4296, 20000)\n",
      "X_test shape:  (6447, 20000)\n",
      "y_train shape: (4296,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ===== 1. LOAD DATA =====\n",
    "train1 = pd.read_csv(\"./SpamEmailDetection/spam_train1.csv\")\n",
    "train2 = pd.read_csv(\"./SpamEmailDetection/spam_train2.csv\")\n",
    "test  = pd.read_csv(\"./SpamEmailDetection/spam_test.csv\")\n",
    "# ===== 2. CLEAN STRUCTURE =====\n",
    "\n",
    "# --- Train 1: ---\n",
    "# v1: label ('ham'/'spam'), v2: message text, other columns mostly NaN\n",
    "train1_clean = train1[['v1', 'v2']].copy()\n",
    "train1_clean = train1_clean.rename(columns={'v1': 'label', 'v2': 'text'})\n",
    "\n",
    "# --- Train 2: ---\n",
    "# label: 'ham'/'spam', text: email body, Unnamed:0 is just an index, label_num is numeric label\n",
    "train2_clean = train2[['label', 'text']].copy()\n",
    "\n",
    "# --- Test: ---\n",
    "# message: text only, no label\n",
    "test_clean = test.rename(columns={'message': 'text'}).copy()\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    # convert to string (in case anything weird got in)\n",
    "    s = str(s)\n",
    "    # lowercase\n",
    "    s = s.lower()\n",
    "    # remove HTML tags\n",
    "    s = re.sub(r'<[^>]+>', ' ', s)\n",
    "    # replace URLs\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', ' url ', s)\n",
    "    # replace email addresses\n",
    "    s = re.sub(r'\\S+@\\S+', ' email ', s)\n",
    "    # remove non-alphanumeric characters (keep some useful symbols)\n",
    "    s = re.sub(r\"[^a-z0-9'$%&*@#\\s]\", \" \", s)\n",
    "    # collapse multiple spaces\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# Apply cleaning\n",
    "train1_clean['clean_text'] = train1_clean['text'].apply(clean_text)\n",
    "train2_clean['clean_text'] = train2_clean['text'].apply(clean_text)\n",
    "test_clean['clean_text']   = test_clean['text'].apply(clean_text)\n",
    "\n",
    "# Combine\n",
    "train_all = pd.concat([train1_clean, train2_clean], ignore_index=True)\n",
    "\n",
    "#map labels to 0/1:\n",
    "label_map = {'ham': 0, 'spam': 1}\n",
    "\n",
    "y_train = train_all['label'].map(label_map).values   # numeric labels\n",
    "X_text_train = train_all['clean_text'].values        # cleaned text for training\n",
    "X_text_test  = test_clean['clean_text'].values       # cleaned text for test\n",
    "\n",
    "\n",
    "# ===== 3. TF-IDF VECTORIZATION =====\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "# Fit on ALL training text, then transform train & test\n",
    "X_train = tfidf.fit_transform(X_text_train)\n",
    "X_test  = tfidf.transform(X_text_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  # (num_train_samples, num_features)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e230e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# Helper function: compute metrics given true labels and predicted probs\n",
    "# =====================================================================\n",
    "def evaluate_model_cv(name, estimator, X, y, cv_splits=5):\n",
    "    \"\"\"\n",
    "    Runs stratified K-fold CV, returns a dict of metrics and prints a summary.\n",
    "    Uses out-of-fold predictions so we get an honest estimate.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name}: Cross-Validation ({cv_splits}-fold) ===\")\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Out-of-fold predicted labels\n",
    "    y_pred = cross_val_predict(estimator, X, y, cv=cv, method='predict')\n",
    "    \n",
    "    # Probabilities (or decision scores) for ROC-AUC\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        y_proba = cross_val_predict(estimator, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "    elif hasattr(estimator, \"decision_function\"):\n",
    "        y_proba = cross_val_predict(estimator, X, y, cv=cv, method='decision_function')\n",
    "    else:\n",
    "        y_proba = y_pred\n",
    "    \n",
    "    acc  = accuracy_score(y, y_pred)\n",
    "    prec = precision_score(y, y_pred, pos_label=1)\n",
    "    rec  = recall_score(y, y_pred, pos_label=1)\n",
    "    f1   = f1_score(y, y_pred, pos_label=1)\n",
    "    try:\n",
    "        roc = roc_auc_score(y, y_proba)\n",
    "    except ValueError:\n",
    "        roc = np.nan\n",
    "    \n",
    "    print(\"Accuracy :\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall   :\", rec)\n",
    "    print(\"F1-score :\", f1)\n",
    "    print(\"ROC-AUC  :\", roc)\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y, y_pred, target_names=[\"Ham (0)\", \"Spam (1)\"]))\n",
    "    \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568f0fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree (base): Cross-Validation (5-fold) ===\n",
      "Accuracy : 0.9117783985102421\n",
      "Precision: 0.7829218106995884\n",
      "Recall   : 0.8191603875134553\n",
      "F1-score : 0.8006312467122567\n",
      "ROC-AUC  : 0.8782466624231963\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.95      0.94      0.94      3367\n",
      "    Spam (1)       0.78      0.82      0.80       929\n",
      "\n",
      "    accuracy                           0.91      4296\n",
      "   macro avg       0.87      0.88      0.87      4296\n",
      "weighted avg       0.91      0.91      0.91      4296\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Decision Tree (base)',\n",
       " 'accuracy': 0.9117783985102421,\n",
       " 'precision': 0.7829218106995884,\n",
       " 'recall': 0.8191603875134553,\n",
       " 'f1': 0.8006312467122567,\n",
       " 'roc_auc': 0.8782466624231963}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================\n",
    "# 2. MODEL SELECTION (base models, no tuning)\n",
    "# ======================================\n",
    "\n",
    "# Decision Tree\n",
    "dt_base = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model_cv(\"Decision Tree (base)\", dt_base, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa5a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (base): Cross-Validation (5-fold) ===\n",
      "Accuracy : 0.9718342644320298\n",
      "Precision: 0.954954954954955\n",
      "Recall   : 0.9128094725511302\n",
      "F1-score : 0.9334067143643369\n",
      "ROC-AUC  : 0.9937198344087472\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.98      0.99      0.98      3367\n",
      "    Spam (1)       0.95      0.91      0.93       929\n",
      "\n",
      "    accuracy                           0.97      4296\n",
      "   macro avg       0.97      0.95      0.96      4296\n",
      "weighted avg       0.97      0.97      0.97      4296\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'SVM (base)',\n",
       " 'accuracy': 0.9718342644320298,\n",
       " 'precision': 0.954954954954955,\n",
       " 'recall': 0.9128094725511302,\n",
       " 'f1': 0.9334067143643369,\n",
       " 'roc_auc': 0.9937198344087472}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM with linear kernel\n",
    "svm_base = SVC(\n",
    "    kernel=\"linear\",\n",
    "    C=1.0,\n",
    "    probability=True,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model_cv(\"SVM (base)\", svm_base, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cd8f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MLP (base): Cross-Validation (5-fold) ===\n",
      "Accuracy : 0.9695065176908753\n",
      "Precision: 0.9761336515513126\n",
      "Recall   : 0.8805166846071044\n",
      "F1-score : 0.9258630447085455\n",
      "ROC-AUC  : 0.9941977842946627\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.97      0.99      0.98      3367\n",
      "    Spam (1)       0.98      0.88      0.93       929\n",
      "\n",
      "    accuracy                           0.97      4296\n",
      "   macro avg       0.97      0.94      0.95      4296\n",
      "weighted avg       0.97      0.97      0.97      4296\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'MLP (base)',\n",
       " 'accuracy': 0.9695065176908753,\n",
       " 'precision': 0.9761336515513126,\n",
       " 'recall': 0.8805166846071044,\n",
       " 'f1': 0.9258630447085455,\n",
       " 'roc_auc': 0.9941977842946627}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple MLP (Neural Network)\n",
    "mlp_base = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,10),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=0.1,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "evaluate_model_cv(\"MLP (base)\",mlp_base, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d92fbd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters: {'C': 1}\n",
      "Best F1 score:   0.9333983822783054\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Tuning grid for Linear SVM\n",
    "# ============================\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "svm = SVC(\n",
    "    kernel=\"linear\",\n",
    "    probability=True,    \n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Run GridSearch\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best F1 score:  \", grid.best_score_)\n",
    "\n",
    "# Retrieve tuned model\n",
    "svm_best = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac45da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on all training data\n",
    "svm_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict test labels\n",
    "y_pred_test = svm_best.predict(X_test)\n",
    "\n",
    "np.savetxt(\"./SpamEmailDetection/Dao_Corona_SpamDectection.txt\", y_pred_test , fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
